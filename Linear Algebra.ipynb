{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Session 0: Linear Algebra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is a simple translation of the linear algebra revision lecture into Python constructs, using numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please note that Python uses 0-based indexing, as does the rest of this notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Notation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$A \\in \\mathbb{R}^{m x n}$ is a matrix with m rows and n columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.49671415, -0.1382643 ,  0.64768854],\n",
       "       [ 1.52302986, -0.23415337, -0.23413696],\n",
       "       [ 1.57921282,  0.76743473, -0.46947439],\n",
       "       [ 0.54256004, -0.46341769, -0.46572975],\n",
       "       [ 0.24196227, -1.91328024, -1.72491783]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = 5\n",
    "n = 3\n",
    "A = np.random.randn(m, n)\n",
    "A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$x \\in \\mathbb{R}^{n}$ is a vector with n rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.56228753, -1.01283112,  0.31424733])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.random.randn(n)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$a_{ij}$ is the entry in the ith row and jth column of A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.76743472915290878"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 2\n",
    "j = 1\n",
    "a_ij = A[i][j]\n",
    "a_ij"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix Multiplication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The product of two matrixes $A \\in \\mathbb{R}^{m x n}$ and $B \\in \\mathbb{R}^{n x p}$ is the matrix \n",
    "\n",
    "$C = AB \\in \\mathbb{R}^{m x p}$ where \n",
    "\n",
    "$C_{ij} = \\sum_{k=1}^{n} A_{ik} B_{kj}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.90802408, -1.4123037 ,  1.46564877, -0.2257763 ,  0.0675282 ,\n",
       "        -1.42474819],\n",
       "       [-0.54438272,  0.11092259, -1.15099358,  0.37569802, -0.60063869,\n",
       "        -0.29169375],\n",
       "       [-0.60170661,  1.85227818, -0.01349722, -1.05771093,  0.82254491,\n",
       "        -1.22084365]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = 6\n",
    "B = np.random.randn(n, p)\n",
    "B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.76547819,  0.48285148,  0.87840781, -0.84915915,  0.64934202,\n",
       "        -1.45808819],\n",
       "       [-1.11459697, -2.61064038,  2.50489606, -0.18418579,  0.05090089,\n",
       "        -1.81578833],\n",
       "       [-1.56925562, -3.01479942,  1.43759548,  0.42834307, -0.74047335,\n",
       "        -1.90068169],\n",
       "       [ 0.03985168, -1.68032411,  1.33487931,  0.19600514, -0.06809894,\n",
       "        -0.06925218],\n",
       "       [ 1.85974361, -3.74897788,  2.58008658,  1.0510195 , -0.25329297,\n",
       "         2.31921156]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C = np.matmul(A, B)\n",
    "C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.76547819,  0.48285148,  0.87840781, -0.84915915,  0.64934202,\n",
       "        -1.45808819],\n",
       "       [-1.11459697, -2.61064038,  2.50489606, -0.18418579,  0.05090089,\n",
       "        -1.81578833],\n",
       "       [-1.56925562, -3.01479942,  1.43759548,  0.42834307, -0.74047335,\n",
       "        -1.90068169],\n",
       "       [ 0.03985168, -1.68032411,  1.33487931,  0.19600514, -0.06809894,\n",
       "        -0.06925218],\n",
       "       [ 1.85974361, -3.74897788,  2.58008658,  1.0510195 , -0.25329297,\n",
       "         2.31921156]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sanity check:\n",
    "C_manual = np.zeros((m, p))\n",
    "for i in range(m):\n",
    "    for j in range(p):\n",
    "        for k in range(n):\n",
    "            C_manual[i][j] += A[i][k] * B[k][j]\n",
    "\n",
    "C_manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 3)\n",
      "(3, 6)\n",
      "(5, 6)\n"
     ]
    }
   ],
   "source": [
    "print(A.shape)\n",
    "print(B.shape)\n",
    "print(C.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vector-Vector Products"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given two vectors $x, y \\in \\mathbb{R}^{n}$, $x^{T}y$, called the inner product or dot product, is a real number given by:\n",
    "\n",
    "$x^{T}y \\in \\mathbb{R} = \\sum_{i=1}^{n} x_{i} y_{i}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.2088636  -1.95967012 -1.32818605]\n",
      "[ 0.19686124  0.73846658  0.17136828]\n"
     ]
    }
   ],
   "source": [
    "x = np.random.randn(n)\n",
    "y = np.random.randn(n)\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.6336427091601982"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.6336427091601982"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sanity check\n",
    "dot_prod = 0\n",
    "for i in range(n):\n",
    "    dot_prod += x[i] * y[i]\n",
    "    \n",
    "dot_prod"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given $x \\in \\mathbb{R}^{m}, y \\in \\mathbb{R}^{n}$\n",
    "\n",
    "$xy^T \\in \\mathbb{R}^{m x n}$ is called the outer product of the vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.11564828 -0.3011037  -1.47852199 -0.71984421 -0.46063877]\n",
      "[ 1.05712223  0.34361829 -1.76304016]\n"
     ]
    }
   ],
   "source": [
    "x = np.random.randn(m)\n",
    "y = np.random.randn(n)\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.12225437, -0.03973886,  0.20389257],\n",
       "       [-0.31830341, -0.10346474,  0.53085791],\n",
       "       [-1.56297846, -0.5080472 ,  2.60669364],\n",
       "       [-0.76096331, -0.24735164,  1.26911425],\n",
       "       [-0.48695148, -0.15828391,  0.81212465]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.outer(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix-Vector Products"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a matrix $A \\in \\mathbb{R}^{m x n}$ and a vector $x \\in \\mathbb{R}^{n}$, their product is a vector \n",
    "\n",
    "$y = Ax \\in \\mathbb{R}^{m}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 3)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.shape # m x n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.32408397, -0.38508228, -0.676922  ])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.random.randn(A.shape[1])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3,)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape # n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.22421439,  0.74225033,  0.53406958,  0.66955167,  1.98282124])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.matmul(A, x)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5,)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape # should be m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix-Matrix Products"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This was already covered above. Some basic properties\n",
    "\n",
    "  * Matrix multiplication is associative, i.e. $ABC = (AB)C = A(BC)$\n",
    "  * Matrix multiplication is distributive, i.e. $A(B + C) = AB + AC$\n",
    "  * Matrix multiplication is **not** commutative, i.e. $AB \\ne BA$ (in general)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Operations and Properties"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Identity Matrix and Diagonal Matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The identity matrix $I_{n} \\in \\mathbb{R}^{n x n}$ is a square matrix with ones on the diagonal and zeros everywhere else"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  0.,  1.]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "I = np.identity(n)\n",
    "I"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It has the property that for all $A \\in \\mathbb{R}^{m x n}$:\n",
    "    \n",
    "$AI_{n} = A = I_{m}A$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.49671415, -0.1382643 ,  0.64768854],\n",
       "       [ 1.52302986, -0.23415337, -0.23413696],\n",
       "       [ 1.57921282,  0.76743473, -0.46947439],\n",
       "       [ 0.54256004, -0.46341769, -0.46572975],\n",
       "       [ 0.24196227, -1.91328024, -1.72491783]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.49671415, -0.1382643 ,  0.64768854],\n",
       "       [ 1.52302986, -0.23415337, -0.23413696],\n",
       "       [ 1.57921282,  0.76743473, -0.46947439],\n",
       "       [ 0.54256004, -0.46341769, -0.46572975],\n",
       "       [ 0.24196227, -1.91328024, -1.72491783]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.matmul(A, np.identity(A.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.49671415, -0.1382643 ,  0.64768854],\n",
       "       [ 1.52302986, -0.23415337, -0.23413696],\n",
       "       [ 1.57921282,  0.76743473, -0.46947439],\n",
       "       [ 0.54256004, -0.46341769, -0.46572975],\n",
       "       [ 0.24196227, -1.91328024, -1.72491783]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.matmul(np.identity(A.shape[0]), A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A diagonal matrix is a matrix where all non-diagonal elements are 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.61167629,  0.        ,  0.        ],\n",
       "       [ 0.        ,  1.03099952,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.93128012]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D = np.identity(n) * np.random.randn(n)\n",
    "D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Transpose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The transpose of a matrix results from \"flipping\" the rows and columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.49671415,  1.52302986,  1.57921282,  0.54256004,  0.24196227],\n",
       "       [-0.1382643 , -0.23415337,  0.76743473, -0.46341769, -1.91328024],\n",
       "       [ 0.64768854, -0.23413696, -0.46947439, -0.46572975, -1.72491783]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A square matrix $A \\in \\mathbb{R}^{n x n}$ is symmetric if $A = A^T$, and anti-symmetric if $A = -A^T$\n",
    "\n",
    "For any matrix $A \\in \\mathbb{R}^{n x n}$, \n",
    "\n",
    "$A + A^T$ is symmetric and $A - A^T$ is anti-symmetric.\n",
    "\n",
    "It follows that any matrix can be represented as a sum of a symmetric and anti-symmetric matrix:\n",
    "\n",
    "$A = \\frac{1}{2}(A + A^T) + \\frac{1}{2}(A - A^T)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.83921752, -0.30921238,  0.33126343],\n",
       "       [ 0.97554513, -0.47917424, -0.18565898],\n",
       "       [-1.10633497, -1.19620662,  0.81252582]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = np.random.randn(n, n)\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.83921752, -0.30921238,  0.33126343],\n",
       "       [ 0.97554513, -0.47917424, -0.18565898],\n",
       "       [-1.10633497, -1.19620662,  0.81252582]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.5*(A + A.T) + 0.5*(A - A.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Trace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The trace of a square matrix $A \\in \\mathbb{R}^{n x n}$, denoted as tr(A) is the sum of the diagonal elements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.50586593867373053"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.trace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.50586593867373053"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr = 0\n",
    "for i in range(n):\n",
    "    tr += A[i][i]\n",
    "    \n",
    "tr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Norms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The norm of a vector $||x||$ is informally a measure of the length of the vector.\n",
    "\n",
    "For example, we have the Euclidean or $l_{2}$ norm:\n",
    "\n",
    "$||x||_{2} = \\sqrt{\\sum_{i=1}^{n} x_{i}^2}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.32408397, -0.38508228, -0.676922  ])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8435295942689488"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(x, ord=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8435295942689488"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(np.dot(x,x.T))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other examples are $l_1$ norm:\n",
    "\n",
    "$||x||_{1} = \\sum_{i=1}^{n} |x_{i}|$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3860882501170702"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(x, ord=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and the infinity norm:\n",
    "\n",
    "$||x||_{\\infty} = max_{i} |x_{i}|$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.67692200030595873"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(x, ord=np.inf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of the above are from the family of $l_p$ norms, which are parameterized by $p \\geq 1$, and defined as \n",
    "\n",
    "$$||x_p|| = \\left( \\sum_{i=1}^{n} |x_{i}^p| \\right)^\\frac{1}{p}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another important one is the Frobenius norm, for matrices\n",
    "\n",
    "$||A||_{F} = \\sqrt{tr(A^T A)}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Independence and Rank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A set of vectors ${x_1, x_2, x_3...}$ are said to be linearly independent if no vector can be represented as a linear combination of the remaining vectors\n",
    "\n",
    "The column rank of a matrix is the size of the largest subset of columns of A that constitute a linearly independent set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[1, 2, 3], [4, 5, 6], [9, 12, 15]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  2,  3],\n",
       "       [ 4,  5,  6],\n",
       "       [ 9, 12, 15]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.matrix_rank(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Inverse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The inverse of a square matrix $A \\in \\mathbb{R}^{n x n}$ is denoted by $A^{-1}$, and is the unique matrix s.t. \n",
    "\n",
    "$A^{-1} A = I = AA^{-1}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.35624003, -0.07201012,  1.0035329 ],\n",
       "       [ 0.36163603, -0.64511975,  0.36139561],\n",
       "       [ 1.53803657, -0.03582604,  1.56464366]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = np.random.randn(n, n)\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.70796683, -0.20849188, -1.68868211],\n",
       "       [ 0.02715442, -1.57233199,  0.3457551 ],\n",
       "       [-2.66129553,  0.16894435,  2.30700572]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_inv = np.linalg.inv(A)\n",
    "A_inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.00000000e+00,   5.05780563e-17,   0.00000000e+00],\n",
       "       [ -1.96993814e-16,   1.00000000e+00,  -1.11022302e-16],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   1.00000000e+00]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.matmul(A, A_inv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.00000000e+00,   3.71549568e-17,  -8.88178420e-16],\n",
       "       [ -6.15912127e-17,   1.00000000e+00,  -1.11022302e-16],\n",
       "       [  4.44089210e-16,  -1.38777878e-17,   1.00000000e+00]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.matmul(A_inv, A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We say that $A$ is invertible or non-singular if $A^{âˆ’1}$ exists and non-invertible or singular otherwise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order for a square matrix A to have an inverse, A must be full rank."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Properties**\n",
    "\n",
    "  * $(A^{-1})^{-1} = A$\n",
    "  * $(AB)^{-1} = B^{-1}A^{-1}$\n",
    "  * $(A^{-1})^T = (A^T)^{-1}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Orthogonal Matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two vectors $x, y \\in \\mathbb{R}^{n}$ are orthogonal if $x^T y = 0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([5, 0, 0]) # vector along x-axis\n",
    "y = np.array([0, 4, 0]) # vector along y-axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 0 0]\n",
      "[0 4 0]\n"
     ]
    }
   ],
   "source": [
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(x.T, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A vector $x$ is normalized if $||x||_2 = 1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([1./np.sqrt(2), 1./np.sqrt(2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99999999999999989"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A square matrix U is orthogonal if all its columns are orthogonal to each other and are normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.70710678,  0.70710678],\n",
       "       [-0.70710678,  0.70710678]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U = np.array([[1./np.sqrt(2), 1./np.sqrt(2)], [-1./np.sqrt(2), 1./np.sqrt(2)]])\n",
    "U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(np.linalg.norm(U[:, 0]))\n",
    "print(np.linalg.norm(U[:, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(U[:, 0], U[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It follows immediately from the definition of orthogonality and normality that \n",
    "\n",
    "$U^T U = I = U U^T$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.],\n",
       "       [ 0.,  1.]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.matmul(U.T, U)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.],\n",
       "       [ 0.,  1.]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.matmul(U, U.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can think about orthogonal matrices as a rotated version of the unit-vectors along the axes in an n-dimensional space.\n",
    "\n",
    "For example, the above U is just 2 vectors along the x and y axes in 2D space, rotated at an angle of 45 degrees."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determinant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The determinant of a square matrix $A \\in \\mathbb{R}^{n x n}$ is a function $\\mathbb{R}^{n x n} \\rightarrow \\mathbb{R}$, denoted as det A or $|A|$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.35624003, -0.07201012,  1.0035329 ],\n",
       "       [ 0.36163603, -0.64511975,  0.36139561],\n",
       "       [ 1.53803657, -0.03582604,  1.56464366]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.36796431478202435"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.det(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eigenvalues and Eigenvectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a square matrix A, we say that $\\lambda \\in \\mathbb{C}$ is an eigenvalue of A and $x \\in \\mathbb{C}^{n}$ is the corresponding eigenvector if\n",
    "\n",
    "$Ax = \\lambda x, x \\ne 0$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intuitively, this definition means that multiplying A by the vector x results in a new vector\n",
    "that points in the same direction as x, but scaled by a factor $\\lambda$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can be re-written as \n",
    "\n",
    "$(\\lambda I - A)x = 0, x \\ne 0$\n",
    "\n",
    "$|\\lambda I - A| = 0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.70710678,  0.70710678],\n",
       "       [-0.70710678,  0.70710678]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.70710678+0.70710678j  0.70710678-0.70710678j]\n",
      "[[ 0.70710678+0.j          0.70710678-0.j        ]\n",
      " [ 0.00000000+0.70710678j  0.00000000-0.70710678j]]\n"
     ]
    }
   ],
   "source": [
    "# Compute the eigenvalues and right eigenvectors of a square array.\n",
    "eigenvalues, eigenvectors = np.linalg.eig(U)\n",
    "print(eigenvalues)\n",
    "print(eigenvectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.70710678+0.70710678j,  0.70710678-0.70710678j])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute the eigenvalues of a general matrix.\n",
    "np.linalg.eigvals(U)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Properties:**\n",
    "\n",
    "  1. The trace of A is equal to the sum of its eigenvalues\n",
    "  2. The determinant of A is equal to the product of its eigenvalues\n",
    "  3. The rank of A is equal to the number of non-zero eigenvalues of A."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.41421356237\n",
      "(1.41421356237+0j)\n"
     ]
    }
   ],
   "source": [
    "print(np.trace(U))\n",
    "print(sum(eigenvalues))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "(1+0j)\n"
     ]
    }
   ],
   "source": [
    "print(np.linalg.det(U))\n",
    "print(np.product(eigenvalues))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "print(np.linalg.matrix_rank(U))\n",
    "print(sum(eigenvalues != 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eigenvalues and Eigenvectors of Symmetric Matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two remarkable properties come about when we look at the eigenvalues and eigenvectors\n",
    "of a symmetric matrix $A \\in \\mathbb{S}^n$.\n",
    "\n",
    "1. All eigenvalues of A are real\n",
    "2. The eigenvectors of A are orthonormal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.40410619, -1.79117709, -0.3869947 ],\n",
       "       [-1.79117709,  0.59224055,  0.02646814],\n",
       "       [-0.3869947 ,  0.02646814, -2.83074148]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = np.random.randn(n, n)\n",
    "A = A + A.T # Use the fact that A + A.T is symmetric\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.6553322  -2.27566224 -3.02227708]\n",
      "[[-0.50924112  0.73664072  0.44501002]\n",
      " [ 0.85922786  0.46461165  0.21415765]\n",
      " [ 0.04899959 -0.4914229   0.86954159]]\n"
     ]
    }
   ],
   "source": [
    "eig_vals, eig_vectors = np.linalg.eig(A)\n",
    "print(eig_vals)\n",
    "print(eig_vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check for orthogonality of the matrix by computing the dot product of every column with every other column. Here is a nifty way to do it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.00000000e+00,  -2.01676762e-17,   6.93889390e-18],\n",
       "       [ -2.01676762e-17,   1.00000000e+00,  -7.21644966e-16],\n",
       "       [  6.93889390e-18,  -7.21644966e-16,   1.00000000e+00]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orth_check = np.matmul(eig_vectors.T, eig_vectors)\n",
    "orth_check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1., -0.,  0.],\n",
       "       [-0.,  1., -0.],\n",
       "       [ 0., -0.,  1.]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Round the really small ones, at a significance level of 13 decimal digits\n",
    "np.around(orth_check, decimals=13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Typically, the matrix of eigenvectors is represented using the letter U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.50924112,  0.73664072,  0.44501002],\n",
       "       [ 0.85922786,  0.46461165,  0.21415765],\n",
       "       [ 0.04899959, -0.4914229 ,  0.86954159]])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U = eig_vectors\n",
    "U"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can therefore represent A as $A = U \\Lambda U^T$, remembering from above that the inverse of an orthogonal matrix is just its transpose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The gradient of f w.r.t. $A \\in \\mathbb{R}^{m x n}$ is the matrix of partial derivatives, of dimensions $m x n$.\n",
    "\n",
    "The gradient of f w.r.t. $x \\in \\mathbb{R}^{n}$ is the matrix of partial derivatives, of dimensions $n$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sympy import symbols, diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, x2, x3 = symbols('x1 x2 x3', real=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2*x1"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff(x1**2 + x2**3 + x3**4, x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff(x1**2 + x2**3 + x3**4, x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4*x3**3"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff(x1**2 + x2**3 + x3**4, x3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff(x1**2 + x2**3 + x3**4, x1, x2, x3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is very important to remember that the gradient of a function is only defined if the function\n",
    "is real-valued, that is, if it returns a scalar value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient(f, x):\n",
    "    \"\"\"Calculates the gradient of a function f w.r.t x\"\"\"\n",
    "    \n",
    "    syms = [x1, x2, x3]\n",
    "    sub_dict = dict(zip(syms, x))\n",
    "    return np.array([diff(f, s).subs(sub_dict) for s in syms])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 4, 6], dtype=object)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp_vector = np.array([1, 2, 3])\n",
    "grads = gradient(x1**2 + x2**2 + x3**2, inp_vector)\n",
    "grads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, this is \"symply\" (eh, eh, get it?) the vector `2x`, which is the derivative of `x**2` (input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 4, 6])"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2*inp_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Least Squares Equation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we have $Ax = b$, where $A \\in \\mathbb{R}^{m x n}$ and $b \\in \\mathbb{R}^{m}$ s.t. $b \\notin R(A)$, then we want to find a vector $x$ such that $Ax$ is as close to b, as measured by the $l_2$ norm. It can be derived that the equation to solve this is:\n",
    "\n",
    "$$x = (A^T A)^{-1} A^Tb$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
