{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Session 02: Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**From Wikipedia**\n",
    "\n",
    "_Decision tree learning uses a decision tree (as a predictive model) to go from observations about an item (represented in the branches) to conclusions about the item's target value (represented in the leaves). It is one of the predictive modelling approaches used in statistics, data mining and machine learning. Tree models where the target variable can take a discrete set of values are called classification trees; in these tree structures, leaves represent class labels and branches represent conjunctions of features that lead to those class labels. Decision trees where the target variable can take continuous values (typically real numbers) are called regression trees._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first define a very basic interface for a decision tree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "class DecisionTree(object):\n",
    "    def __init__(self, split_scorer):\n",
    "        ...\n",
    "\n",
    "    def fit(self, data):\n",
    "        ...\n",
    "\n",
    "    def predict(self, row):\n",
    "        ...\n",
    "```\n",
    "\n",
    "The `split_scorer` will be a callback which will allow us to determine which feature to split on next."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a basic API defined, we can write a few scorer functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(df, feature):\n",
    "    \"\"\"Returns an array of non-overlapping dataframes, the union of which is the original\"\"\"\n",
    "    return [x for _, x in df.groupby(feature)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gini Impurity**\n",
    "\n",
    "$G = \\sum_{k=1}^{N} p_i (1 - p_i)$\n",
    "\n",
    "Equivalent form:\n",
    "\n",
    "$G = 1 - \\sum_{k=1}^{N} p_i^2$\n",
    "\n",
    "The Gini index is referred to as a measure of node purity—a small value indicates that a node contains predominantly observations from a single class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gini_impurity(target):\n",
    "    c = Counter(target)\n",
    "    frequencies = np.array(list(c.values()))\n",
    "    n = frequencies.sum()\n",
    "    pi = frequencies / n\n",
    "    return 1 - sum(pi**2)\n",
    "\n",
    "def gini_impurity_scorer(df, target_label):\n",
    "    \"\"\"Given a dataframe with the target label, determine the feature that gives the best split\n",
    "        using the Gini impurity as a measure\n",
    "    \"\"\"\n",
    "    target = df[target_label]\n",
    "    features = df.drop(target_label, axis=1).columns\n",
    "    \n",
    "    gini_before = gini_impurity(df[target_label])\n",
    "    \n",
    "    best_feature = None\n",
    "    \n",
    "    for feature in features:\n",
    "        df_split = split(df, feature)\n",
    "        gini_after = np.mean([gini_impurity(sub_df[target_label]) for sub_df in df_split])\n",
    "        if gini_after < gini_before:\n",
    "            best_feature = feature\n",
    "            \n",
    "    return best_feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Information Gain = entropy(parent) – weighted average entropy(children)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(target):\n",
    "    c = Counter(target)\n",
    "    frequencies = np.array(list(c.values()))\n",
    "    n = frequencies.sum()\n",
    "    pi = frequencies / n\n",
    "    return -np.sum(pi*np.log2(pi))\n",
    "\n",
    "def weighted_entropy(targets):\n",
    "    n = sum(len(t) for t in targets)\n",
    "    weights = np.array([len(t)/n for t in targets])\n",
    "    entropies = [entropy(target) for target in targets]\n",
    "    return -np.dot(weights, entropies)\n",
    "\n",
    "def information_gain(df, target_label):\n",
    "    \"\"\"Given a dataframe with the target label, determine the feature that gives the best split\n",
    "        using the Information Gain as a measure\n",
    "    \"\"\"\n",
    "    target = df[target_label]\n",
    "    features = df.drop(target_label, axis=1).columns\n",
    "    \n",
    "    parent_entropy = entropy(target)\n",
    "    \n",
    "    best_feature = None\n",
    "    ig_max = -np.inf\n",
    "    \n",
    "    for feature in features:\n",
    "        df_split = split(df, feature)\n",
    "        targets = [df_subset[target_label] for df_subset in df_split]\n",
    "        child_entropy = weighted_entropy(targets)\n",
    "        info_gain = parent_entropy - child_entropy\n",
    "        if info_gain > ig_max:\n",
    "            ig_max = info_gain\n",
    "            best_feature = feature\n",
    "            \n",
    "    return best_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"x\": [1,1,1,1,2,2,2,1,1,1,3], \"y\": [2,2,2,2,3,3,1,2,2,2,4]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a few scorers avaliable, we can now sketch out an initial implementation of a decision tree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTree(object):\n",
    "    def __init__(self, split_scorer):\n",
    "        self.scorer = split_scorer\n",
    "        self.tree = {}\n",
    "        \n",
    "    def _majority(self, data, target_label):\n",
    "        return data[target_label].value_counts().idxmax()\n",
    "\n",
    "    def _fit(self, data, target_label):\n",
    "        features = data.drop(target_label, axis=1).columns.tolist()\n",
    "        \n",
    "        # Stopping criterion is when we have only a single class label left\n",
    "        if len(set(data[target_label])) == 1: return data[target_label].iloc[0]\n",
    "\n",
    "        # Or we don't have any features left to split on, in which case we will just predict majority:\n",
    "        if not features: return self._majority(data, target_label)\n",
    "        \n",
    "        # You could also put in a condition here for the depth of the tree as a stopping criterion\n",
    "        \n",
    "        # Decide which is the best feature to split on using the split scorer\n",
    "        best_feature = self.scorer(data, target_label)\n",
    "        \n",
    "        # Split on the best feature\n",
    "        splits = split(data, best_feature)\n",
    "        \n",
    "        # Start a (sub) tree\n",
    "        current_node = {best_feature: {}}\n",
    "\n",
    "        # For every value that this feature can take, we fit a sub-tree to that subset of data \n",
    "        for val in set(data[best_feature]):\n",
    "            data_subset = data[data[best_feature] == val].drop(best_feature, axis=1)\n",
    "\n",
    "            # Recursively fit trees for each split value of this feature\n",
    "            current_node[best_feature][val] = self._fit(data_subset, target_label)\n",
    "\n",
    "        return current_node\n",
    "                        \n",
    "    def fit(self, data, target_label):\n",
    "        self.tree = self._fit(data, target_label)\n",
    "\n",
    "    def predict(self, row):\n",
    "        ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars = pd.read_csv('car.csv', names=['buying', 'maint', 'doors', 'persons', 'lug_boot', 'safety', 'evaluation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>buying</th>\n",
       "      <th>maint</th>\n",
       "      <th>doors</th>\n",
       "      <th>persons</th>\n",
       "      <th>lug_boot</th>\n",
       "      <th>safety</th>\n",
       "      <th>evaluation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>low</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>high</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>med</td>\n",
       "      <td>low</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>med</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  buying  maint doors persons lug_boot safety evaluation\n",
       "0  vhigh  vhigh     2       2    small    low      unacc\n",
       "1  vhigh  vhigh     2       2    small    med      unacc\n",
       "2  vhigh  vhigh     2       2    small   high      unacc\n",
       "3  vhigh  vhigh     2       2      med    low      unacc\n",
       "4  vhigh  vhigh     2       2      med    med      unacc"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cars.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTree(gini_impurity_scorer)\n",
    "dt.fit(cars, 'evaluation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt.tree"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
